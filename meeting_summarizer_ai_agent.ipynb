{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXC-NIXXdr5R",
        "outputId": "d6195bd2-73bb-461a-88e7-7d2952fc2fad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GROQ set: True\n",
            "GEMINI set: True\n"
          ]
        }
      ],
      "source": [
        "#Read Colab secrets and export to env vars expected by the notebook\n",
        "# Read Colab secrets and export to env vars expected by the notebook\n",
        "import os\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "except Exception:\n",
        "    userdata = None\n",
        "\n",
        "def _get(*names):\n",
        "    for n in names:\n",
        "        try:\n",
        "            v = userdata.get(n) if userdata else None\n",
        "        except Exception:\n",
        "            v = None\n",
        "        if v:\n",
        "            return v.strip()\n",
        "    return None\n",
        "\n",
        "groq = _get(\"GROQ_API_KEY\", \"GROQ_API\")\n",
        "gemini = _get(\"GEMINI_API_KEY\", \"GEMINI_API\", \"GOOGLE_API_KEY\")\n",
        "\n",
        "if groq:  os.environ[\"GROQ_API_KEY\"] = groq\n",
        "if gemini: os.environ[\"GEMINI_API_KEY\"] = gemini\n",
        "\n",
        "print(\"GROQ set:\", bool(os.environ.get(\"GROQ_API_KEY\")))\n",
        "print(\"GEMINI set:\", bool(os.environ.get(\"GEMINI_API_KEY\")))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.environ.get(\"GROQ_API_KEY\", \"\")[:6] + \"‚Ä¶\")\n",
        "print(os.environ.get(\"GEMINI_API_KEY\", \"\")[:6] + \"‚Ä¶\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kees_hkLeROf",
        "outputId": "76f30bb9-60a1-4ee1-8387-a9a5e8aae69b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gsk_VS‚Ä¶\n",
            "AIzaSy‚Ä¶\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Install + Imports\n",
        "!pip -q install gradio groq google-generativeai pandas python-dateutil dateparser\n",
        "\n",
        "import os, re, json, tempfile\n",
        "import gradio as gr\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import dateparser\n",
        "\n",
        "USE_GROQ = bool(os.environ.get(\"GROQ_API_KEY\"))\n",
        "USE_GEMINI = bool(os.environ.get(\"GEMINI_API_KEY\"))\n",
        "\n",
        "if not (USE_GROQ or USE_GEMINI):\n",
        "    print(\"üîë Set at least one key before running: \"\n",
        "          \"os.environ['GROQ_API_KEY']='...' or os.environ['GEMINI_API_KEY']='...'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dGwuH78fjgc",
        "outputId": "11694d9b-4cf4-425a-ce2d-843cb27440f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/134.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/315.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m315.5/315.5 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title LLM helper\n",
        "def llm_call(system: str, user: str, temperature: float = 0.2) -> str:\n",
        "    if USE_GROQ:\n",
        "        from groq import Groq\n",
        "        client = Groq(api_key=os.environ[\"GROQ_API_KEY\"])\n",
        "        resp = client.chat.completions.create(\n",
        "            model=\"llama-3.1-8b-instant\",\n",
        "            messages=[{\"role\": \"system\", \"content\": system},\n",
        "                      {\"role\": \"user\", \"content\": user}],\n",
        "            temperature=temperature,\n",
        "        )\n",
        "        print(\"resp:\", resp)\n",
        "        return resp.choices[0].message.content.strip()\n",
        "\n",
        "    if USE_GEMINI:\n",
        "        import google.generativeai as genai\n",
        "        genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
        "        model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "        prompt = f\"System:\\n{system}\\n\\nUser:\\n{user}\"\n",
        "        resp = model.generate_content(prompt)\n",
        "        return resp.text.strip()\n",
        "\n",
        "    raise RuntimeError(\"No API key found. Set GROQ_API_KEY or GEMINI_API_KEY.\")"
      ],
      "metadata": {
        "id": "e-XitcRFgDEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Agent logic\n",
        "SYSTEM_PROMPT = \"\"\"You are a precise Meeting Notes Assistant.\n",
        "Given raw notes, return a compact JSON with:\n",
        "- summary: exactly 3 bullet points (short phrases).\n",
        "- decisions: list of decisions (0..5 concise items).\n",
        "- action_items: list of objects with keys:\n",
        "  task (imperative), owner (first name or role), due_date (natural language OK),\n",
        "  priority (High|Medium|Low). Only include real, actionable tasks.\n",
        "- email_subject: short subject line for a follow-up email.\n",
        "- email_body: 120-180 words, crisp recap + action items with owners & due dates.\n",
        "STRICTLY return only a JSON object. No code fences, no commentary.\n",
        "Keep writing professional, friendly, and unambiguous.\n",
        "\"\"\"\n",
        "\n",
        "USER_TEMPLATE = \"\"\"MEETING:\n",
        "Title: {title}\n",
        "DateTime (local): {meeting_dt}\n",
        "Notes:\n",
        "{notes}\n",
        "\n",
        "Constraints:\n",
        "- summary: exactly 3 bullets.\n",
        "- If a due date is hinted (e.g., ‚Äúnext Friday‚Äù), include it; else use \"TBD\".\n",
        "- Prioritize tasks that move metrics or remove blockers.\n",
        "Return only the JSON object.\n",
        "\"\"\"\n",
        "\n",
        "ALLOWED_PRIORITIES = {\"High\",\"Medium\",\"Low\"}\n",
        "\n",
        "def parse_json_loose(text: str) -> dict:\n",
        "    m = re.search(r\"\\{.*\\}\", text, flags=re.S)\n",
        "    candidate = m.group(0) if m else text\n",
        "    return json.loads(candidate)\n",
        "\n",
        "def normalize_due_date(due_str: str, base_dt: datetime) -> str:\n",
        "    if not due_str or due_str.strip().upper() == \"TBD\":\n",
        "        return \"TBD\"\n",
        "    dt = dateparser.parse(\n",
        "        due_str,\n",
        "        settings={\"RELATIVE_BASE\": base_dt, \"PREFER_DATES_FROM\": \"future\"}\n",
        "    )\n",
        "    return dt.date().isoformat() if dt else due_str"
      ],
      "metadata": {
        "id": "llqSwihgjD1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Gradio UI (runs in Colab)\n",
        "def run_agent(title, meeting_dt, notes):\n",
        "    # Fallbacks\n",
        "    title = (title or \"Team Sync\").strip()\n",
        "    meeting_dt = (meeting_dt or datetime.now().strftime(\"%Y-%m-%d %H:%M\")).strip()\n",
        "    notes = (notes or \"\").strip()\n",
        "\n",
        "    user = USER_TEMPLATE.format(title=title, meeting_dt=meeting_dt, notes=notes)\n",
        "    raw = llm_call(SYSTEM_PROMPT, user)\n",
        "\n",
        "    try:\n",
        "        js = parse_json_loose(raw)\n",
        "    except Exception as e:\n",
        "        return (\"\", f\"‚ö†Ô∏è Could not parse model output:\\n{raw}\\n\\nError: {e}\",\n",
        "                pd.DataFrame(), None)\n",
        "\n",
        "    # Normalize action items\n",
        "    try:\n",
        "        base_dt = datetime.fromisoformat(meeting_dt.replace(\"Z\",\"\").strip())\n",
        "    except:\n",
        "        base_dt = datetime.now()\n",
        "\n",
        "    for item in js.get(\"action_items\", []):\n",
        "        pr = str(item.get(\"priority\",\"\")).title()\n",
        "        item[\"priority\"] = pr if pr in ALLOWED_PRIORITIES else \"Medium\"\n",
        "        item[\"due_date\"] = normalize_due_date(item.get(\"due_date\",\"\"), base_dt)\n",
        "\n",
        "    # Build outputs\n",
        "    summary_md = \"### Summary (3 bullets)\\n\" + \"\\n\".join([f\"- {b}\" for b in js.get(\"summary\", [])])\n",
        "    decisions = js.get(\"decisions\", [])\n",
        "    decisions_md = \"### Decisions\\n\" + (\"\\n\".join([f\"- {d}\" for d in decisions]) if decisions else \"- (none)\")\n",
        "\n",
        "    # Dataframe + CSV\n",
        "    rows = []\n",
        "    for i, ai in enumerate(js.get(\"action_items\", []), 1):\n",
        "        rows.append({\n",
        "            \"idx\": i,\n",
        "            \"task\": ai.get(\"task\",\"\"),\n",
        "            \"owner\": ai.get(\"owner\",\"\"),\n",
        "            \"due_date\": ai.get(\"due_date\",\"\"),\n",
        "            \"priority\": ai.get(\"priority\",\"\"),\n",
        "        })\n",
        "    ai_df = pd.DataFrame(rows) if rows else pd.DataFrame(columns=[\"idx\",\"task\",\"owner\",\"due_date\",\"priority\"])\n",
        "\n",
        "    csv_path = None\n",
        "    if len(ai_df) > 0:\n",
        "        tmp = tempfile.NamedTemporaryFile(delete=False, suffix=\".csv\")\n",
        "        ai_df.to_csv(tmp.name, index=False)\n",
        "        csv_path = tmp.name\n",
        "\n",
        "    email_block = f\"*Subject:* {js.get('email_subject','')}\\n\\n{js.get('email_body','')}\"\n",
        "    return summary_md + \"\\n\\n\" + decisions_md, email_block, ai_df, csv_path\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## Meeting Minutes ‚Üí Action-Items Agent (Colab-friendly, Groq/Gemini)\")\n",
        "    with gr.Row():\n",
        "        title_in = gr.Textbox(label=\"Meeting Title\", value=\"Q3 Growth Marketing Sync\")\n",
        "        dt_in = gr.Textbox(label=\"Meeting Date/Time (local)\", value=datetime.now().strftime(\"%Y-%m-%d %H:%M\"))\n",
        "    notes_in = gr.Textbox(label=\"Raw Notes\", lines=12, placeholder=\"Paste raw notes here...\")\n",
        "\n",
        "    run_btn = gr.Button(\"Extract Summary, Decisions, Action Items\")\n",
        "\n",
        "    out_summary = gr.Markdown()\n",
        "    out_email   = gr.Markdown()\n",
        "    out_table   = gr.Dataframe(headers=[\"idx\",\"task\",\"owner\",\"due_date\",\"priority\"], interactive=False)\n",
        "    out_file    = gr.File(label=\"Download Action Items CSV\")\n",
        "\n",
        "    run_btn.click(run_agent, inputs=[title_in, dt_in, notes_in],\n",
        "                  outputs=[out_summary, out_email, out_table, out_file])\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "INtd7VP5mV2Y",
        "outputId": "9d2a3144-d323-4af6-e7f5-37d1d5098811"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://fb7d8343efc779e72c.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://fb7d8343efc779e72c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fEYp6eI_mgcb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}